<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
<title>Transformer2 : Self-adaptive LLMs (AI論文要約)</title>

  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-127416809-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-127416809-1');
  </script>
  


<script
  data-ad-client="ca-pub-7303877370233278"
  async
  src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"
></script>

<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="alternate"
  type="application/rss+xml"
  href="https://www.if-blog.siteindex.xml"
  title="アンドロイドは推理小説を書くか?"
/>

<link rel="stylesheet" href="https://www.if-blog.site/fontawesome/css/all.min.css" />




<link
  crossorigin="anonymous"
  href="/css/styles.min.css"
  integrity=""
  rel="preload stylesheet"
  as="style"
/>




<link
  id="dark-mode-theme"
  crossorigin="anonymous"
  href="/css/dark.min.css"
  integrity=""
  rel="preload stylesheet"
  as="style"
/>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>


<script>
  var darkTheme = document.getElementById('dark-mode-theme')
  var storedTheme = localStorage.getItem('dark-mode-storage')

  if (storedTheme === 'dark') {
    darkTheme.disabled = false
  } else if (storedTheme === 'light') {
    darkTheme.disabled = true
  }
</script>


<script defer crossorigin="anonymous" src="/js/theme.js" integrity=""></script>


<script defer crossorigin="anonymous" src="/js/instantpage.min.js" integrity=""></script>

  
    <meta name="description" content="AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。
https://arxiv.org/abs/2501.06252
どんなもの Transformer2は、未学習のタスクに対してリアルタイムでLarge Language Models (LLMs) を適応させるための自己適" />
  


<meta name="generator" content="Hugo 0.110.0">
  </head>
  <body>
    
  




  <header>
    <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
        
          <li>
            <a href="/" name="Home" class="tooltip"
              ><i class="fas fa-home fa-lg"></i>
              <span>Home</span>
            </a>
          </li>
          
      
        
          <li>
            <a href="/pages/about" name="About" class="tooltip"
              ><i class="fas fa-user fa-lg"></i>
              <span>About</span>
            </a>
          </li>
          
      
        
          <li>
            <a href="/tags" name="Tags" class="tooltip"
              ><i class="fas fa-tag fa-lg"></i>
              <span>Tags</span>
            </a>
          </li>
          
      
        
          <li>
            <a href="/pages/search" name="Search" class="tooltip"
              ><i class="fas fa-search fa-lg"></i>
              <span>Search</span>
            </a>
          </li>
          
      
    </ul>
  </div>
</nav>

    <div class="intro-header">
      <div class="container">
        <div class="posts-heading">
          
            

              
              <h1>
		
		Transformer2 : Self-adaptive LLMs (AI論文要約)
		
		
                </h1>
              

              

              
            
          
          
          
          
        </div>
      </div>
    </div>
  </header>
  

    
  <div class="container" role="main">
    <article class="article" class="blog-post">
      
        <div class="blog-tags">
          <i class="fas fa-tag" style="color:#111111"></i>
          
            <a href="https://www.if-blog.site/tags/nlp/">nlp</a
            >&nbsp;
          
            <a href="https://www.if-blog.site/tags/deeplearning/">deeplearning</a
            >&nbsp;
          
        </div>
      

      
        <div style="margin-bottom: 10px;">
          <i class="fa fa-calendar-alt"></i
          >&nbsp;2025-01-18
        </div>
      

      


      <div class="article-main">
        <p>AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。</p>
<p><a href="https://arxiv.org/abs/2501.06252">https://arxiv.org/abs/2501.06252</a></p>
<h2 id="どんなもの">どんなもの</h2>
<p>Transformer2は、未学習のタスクに対してリアルタイムでLarge Language Models (LLMs) を適応させるための自己適応フレームワークです。重み行列の特異値成分のみを選択的に調整することで、計算コストの高い従来のファインチューニング手法の課題を解決します。推論時には、まずディスパッチシステムがタスクのプロパティを識別し、次に強化学習 を用いて訓練されたタスク固有の「専門家」ベクトルを動的に混合して、入力プロンプトに対するターゲットとなる動作を得ます。</p>
<h2 id="先行研究と比べてどこがすごいの">先行研究と比べてどこがすごいの？</h2>
<p>Transformer2は、LoRAなどの従来手法と比べて、より少ないパラメータ数と高い効率性で、優れた性能を発揮します。  従来のファインチューニングは計算コストが高く、多様な タスクへの対応が静的なのに対し、Transformer2はリアルタイムで適応できる点が優れています。また、異なるLLMアーキテクチャやモダリティ（ビジョン言語タスクなど）にも対応できる汎用性を持ちます。先行研究のMixture of Experts (MoE)とは異なり、サンプルレベルのモジュール選択戦略を採用し、強化学習を用いてドメイン固有の知識を獲得した 「専門家」ベクトルを生成する点が異なります。  さらに、Singular Value Fine-tuning (SVF)という新しいパラメータ効率の良いファインチューニング手法を用いることで、少 ないデータ量でも過学習のリスクを抑え、計算コストを削減しています。</p>
<h2 id="技術や手法のきもはどこにある">技術や手法のきもはどこにある？</h2>
<p>Transformer2の核となる技術は、<strong>Singular Value Fine-tuning (SVF)</strong> と <strong>二段階推論メカニズム</strong> です。</p>
<p>SVFは、モデルの重み行列$W \in \mathbb{R}^{n \times m}$の特異値分解$W = U\Sigma V^T$を利用し、特異値$\Sigma$のスケールのみを調整する手法です。  これにより、学習パラメータ数を大幅に削減し、過学習を防ぎ、かつ、各特異値成分が独立に処理されるため、構成可能性が高まります。  学習されたベクトル$z \in \mathbb{R}^r$を用いて、新し い重み行列$W&rsquo; = U\Sigma&rsquo;V^T$ ($\Sigma&rsquo; = \Sigma \otimes \text{diag}(z)$) を生成します。</p>
<p>強化学習を用いて、タスクパフォーマンスを直接最適化することで、効率的にドメイン特異的な「専門家」ベクトルを学習します。目的関数は以下の通りです。</p>
<p>$$
J(\theta_z) = \mathbb{E} \left[ \log \pi_{\theta_{W&rsquo;}}(\hat{y}_i | x_i) \right] r(\hat{y}_i, y_i)
$$</p>
<p>$$
- \lambda D_{KL}(\pi_{\theta_{W&rsquo;}} | \pi_{\theta_W})
$$</p>
<p>ここで、$\theta_z = {z_1, \dots, z_{N \times M}}$ は学習するSVFベクトルの集合、$\theta_W = {W_1, \dots, W_{N \times M}}$は重み行列の集合、$r(\hat{y}_i, y_i)$ は報酬、$\lambda$はKLペナルティの係数です。</p>
<p>二段階推論メカニズムでは、第一段階でモデルを実行し、タスク特性を識別します。第二段階で、第一段階で得られた情報に基づいて、学習済みの「専門家」ベクトルを組み合わ せ、LLMの基本的な重みを調整します。  論文では、プロンプトエンジニアリング、分類器ベース、Few-shot適応の3つの適応戦略が提案されています。</p>
<h2 id="どうやって有効だと検証した">どうやって有効だと検証した？</h2>
<p>様々なLLM (LLAMA3-8B-INSTRUCT, MISTRAL-7B-INSTRUCT-V0.3, LLAMA3-70B-INSTRUCT)とタスク(GSM8K, MBPP-pro, ARC-Easy, MATH, Humaneval, ARC-Challenge, OKVQA)を用いて、SVFとTransformer2の有効性を検証しました。</p>
<p>SVFは、LoRAと比較して、少ないパラメータ数で高い性能を示しました。Transformer2は、様々な適応戦略を用いて、未学習のタスクに対しても高い適応能力を示しました。特に、Few-shot適応戦略では、テスト時の条件へのアクセスが増えるにつれて性能が向上することが確認されました。  ビジョン言語タスクに対しても、言語タスクで学習した専門家ベ クトルを用いて性能向上を確認しています。</p>
<h2 id="議論はあるか">議論はあるか</h2>
<ul>
<li><strong>CEMベースの適応戦略の効率性:</strong>  CEMを用いたFew-shot適応は、性能向上に寄与しますが、多くの専門ドメインへの拡張には、一度限りの計算コストの増加が課題となります。しかし、性能向上と自己適応能力の向上によるメリットによって相殺されると主張されています。</li>
<li><strong>SVF専門家の能力の限界:</strong> SVF専門家の能力は、ベースモデルの潜在的な成分に依存します。モデルの統合技術が、この問題を解決する可能性があると示唆されています。</li>
<li><strong>クロスモデル互換性:</strong> 異なるLLM間でのSVF専門家ベクトルの転移可能性は、モデルアーキテクチャの類似性に依存する可能性があり、さらなる研究が必要です。</li>
</ul>

      </div>
      <div class="related-article">
        

  <h2>See Also</h2>
  <ul>
    
      <li><a href="/posts/paper/paper16/">Language Model Can Listen While Speaking (AI論文要約)</a></li>
    
      <li><a href="/posts/paper/paper13/">MiniMax-01: Scaling Foundation Models with Lightning Attention (AI論文要約)</a></li>
    
      <li><a href="/posts/paper/paper10/">SentenceVAE: Enable Next-sentence Prediction for Large Language Models with Faster Speed, Higher Accuracy and Longer Context (AI論文要約)</a></li>
    
      <li><a href="/posts/paper/paper15/">Small Language Models (SLMs) Can Still Pack a Punch: A survey (AI論文要約)</a></li>
    
      <li><a href="/posts/paper/paper14/">Tensor Product Attention Is All You Need (AI論文要約)</a></li>
    
  </ul>


      </div>
    </article>
    
    
    
      

    
  </div>

    <footer>
  
  <div>
    
      <a href="https://twitter.com/if_004" name="twitter"
        ><i class="fab fa-twitter"></i
      ></a>
    
  </div>


  <div class="container">
    <div class="credits copyright">
      <a href="https://www.if-blog.site/pages/about">if_004</a>
      &nbsp;&copy;
      2025
      
        &nbsp;/&nbsp;
        <a href="https://www.if-blog.site">アンドロイドは推理小説を書くか?</a>
      
      &nbsp;&ndash;&nbsp;
      <i class="fas fa-moon" id="dark-mode-toggle"></i>

      <p class="credits theme-by">
         <a href="https://gohugo.io">Hugo</a>&nbsp;Theme
        <a href="https://github.com/matsuyoshi30/harbor">Harbor</a>
      </p>
    </div>
  </div>
</footer>

  </body>
</html>
