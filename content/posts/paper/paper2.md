---
title: "Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering (AI論文要約)"
slug: "paper2"
tags: ["nlp","deeplearning", "paper_summary"]
date: "2025-01-02T11:00:00+09:00"
draft: false
---

AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。

https://arxiv.org/abs/2410.15999

## どんなもの

本論文は、大規模言語モデル (LLM) の知識選択行動を、事前学習済みスパースオートエンコーダ (SAE) を用いた表現エンジニアリング手法 SPARE を通じて制御する手法を提案し ている。LLM はパラメータ内に多くの事実的知識を保持するが、文脈情報と矛盾する可能性があり、その結果、古いまたは不正確な情報への依存といった望ましくない挙動につながる。SPARE は、LLM の内部活性化を推論時に編集することで、文脈知識とパラメータ知識のどちらを使用するかを制御する。

## 先行研究と比べてどこがすごいの？

既存の表現エンジニアリング手法は、LLM の内部活性化（隠れ状態や MLP 活性化など）を直接変更するが、これらの活性化は多義的な高密度ベクトルであり、正確な調整が難しい 。本研究では、事前学習済み SAE を用いることで、多義的な活性化を多数の単義的な特徴に分解し、より正確な活性化編集を可能にしている。その結果、既存の表現エンジニアリ ング手法やコントラスティブデコーディング手法よりも、知識衝突時の知識選択行動の制御において高い精度を達成している（それぞれ+10%、+15%の向上）。

## 技術や手法のきもはどこにある？

SPARE の核心は、事前学習済み SAE を用いた表現エンジニアリングにある。具体的には以下の3つのステップからなる：

1. 異なる知識選択行動につながる活性化の収集: 知識衝突を引き起こす入力インスタンスを、モデルの予測に基づいて、文脈知識を選択したグループとパラメータ知識を選択 したグループに分割する。それぞれのグループから、回答の最初のトークンを予測するために使用される最後の位置の隠れ状態を収集する。

1. 機能的 SAE 活性化の特定: 収集した隠れ状態を SAE でエンコードし、各 SAE 活性化と知識選択行動間の相互情報量を計算する。相互情報量が高い上位 k 個の活性化を、 知識選択行動を制御する機能的活性化として選択する。

1. 活性化の編集による行動の制御: 機能的活性化に基づき、推論時にLLMの隠れ状態を編集する。望ましくない知識選択行動に関連する特徴を除去し、望ましい知識選択行動 に関連する特徴を追加する。この編集は、SAE のデコーダを用いて行われ、元の隠れ状態の情報を可能な限り保持するように設計されている。

## どうやって有効だと検証した？

オープン・ドメイン質問応答 (ODQA) タスクにおいて、NQSwap と Macnoise データセットを用いて実験を行った。SPARE を、既存の表現エンジニアリング手法（TaskVec、ActAdd、SEA）、コントラスティブデコーディング手法（DoLa、CAD）、インコンテキスト学習 (ICL) と比較した。評価指標として、文脈知識とパラメータ知識のそれぞれを使用するように 制御した際の正解率 (EM) を用いた。その結果、SPARE はすべてのベースライン手法を上回り、知識選択行動の制御において高い有効性を示した。さらに、行動変化能力、介入の負の影響、そして ablation study を通じて、SPARE の有効性を多角的に検証している。

## 議論はあるか

論文ではいくつかの限界が指摘されている。

- SAE の事前学習への依存: SPARE は事前学習済み SAE に依存するため、事前学習済み SAE が利用できないモデルには適用できない。

- タスクへの汎化性: ODQA タスクに限定された実験結果であり、他のタスクや複雑な推論、マルチホップ質問、長文生成などへの汎化性は不明である。

- 知識ソース選択の二値化: 知識ソースの信頼性の判断を二値化しており、実際にはより複雑な判断が必要となる可能性がある。

全体として、SPARE はLLMの知識選択行動を効果的に制御する有望な手法であるが、さらなる研究が必要であることが示唆されている。特に、SAE の事前学習の必要性の軽減や、よ り広範なタスクへの適用可能性の検証が今後の課題となる。