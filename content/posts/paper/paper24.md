---
title: "Texygen: A Benchmarking Platform for Text Generation Models"
slug: "paper24"
tags: ["nlp","deeplearning", "paper_summary", "データセット指標"]
date: "2025-05-21T20:00:00+09:00"
draft: false
---

AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。

https://arxiv.org/abs/1802.01886

## サマリー
本論文では、オープン ドメイン テキスト生成モデルの研究を支援するためのベンチマーク プラットフォームである Texygen を紹介する。Texygen は、多数のテキスト生成モデルを実装しているだけでなく、生成されたテキストの多様性、品質、一貫性を評価する一連のメトリクスもカバーしている。このプラットフォームは、テキスト生成に関する研究の標準化、研究者間での微調整されたオープンソース実装の共有の促進、そして将来の研究作業の再現性と信頼性の向上に貢献することを目指している。

## 主要なテーマと重要なアイデア
* **オープン ドメイン テキスト生成の課題**: 論文では、テキスト生成における3つの主要な課題を指摘している。第一に、優れたテキスト生成モデルの基準が明確でないこと。第二に、研究者がソースコードを公開する義務がないため、報告された実験結果の再現が困難であること。第三に、テキスト生成は品質と多様性のトレードオフ問題に悩まされており、モード崩壊によって出力が限定的なパターンに縮小する可能性があることである。
* **Texygen プラットフォーム**: この課題に対応するため、Texygen プラットフォームが提案された。Texygen は、テキスト生成モデルの標準化されたトップダウンの多次元評価システムを提供する。プラットフォームは、適切にトレーニングされたベースラインモデルと、自動的に計算可能な評価メトリクスの2つの要素で構成されている。
    * **ベースラインモデル**: Texygen には、vanilla MLE、SeqGAN、MaliGAN、RankGAN、TextGAN、GSGAN、LeakGAN など、さまざまな尤度ベースのモデル、敵対的メソッド、階層的メソッドが含まれている。
        * Vanilla MLE: $max_{\theta}\sum_{x}\sum_{t}log~\pi_{\theta}(x_{t}|s_{t})$
        * SeqGAN: ジェネレーターは REINFORCE アルゴリズムを使用して GAN の目的関数を最適化する: {{< math >}}$$min_{\phi}-\bigoplus_{Y\sim p_{datu}}[log~D_{\phi}(Y)]-\mathbb{R}_{Y-G_{\theta}}[log(1-D_{\phi}(Y))]$${{< /math >}}
        * MaliGAN: 報酬をリスケールする: $r_{D}(x_{i})^{\prime}=\frac{r_{D}(x_{i})}{\sum_{f=1}^{m}r_{D}(x_{f})}-b$。
        * RankGAN: ランキング損失を最適化する: {{< math >}}$L_{\phi}=\mathbb{E}_{s\sim p_{data}}[log~R_{\phi}(s|U,C^{-})]-\mathbb{E}_{s\sim G_{\theta}}[log~R_{\phi}(s|U,C^{+})]${{< /math >}}。
        * GSGAN: Gumbel Softmax トリックを使用する: arg max [softmax(h+g)] ~ softmax(h)。
        * TextGAN: MMD 損失を最適化する: $L_{recon}=||z-\hat{z}||$。
        * LeakGAN: Manager と Worker の2つのモジュールを持つ階層型強化学習フレームワーク。
    * **評価メトリクス**: Texygen は、BLEU、EmbSim、NLL-oracle、NLL-test、Self-BLEUという5つのテキスト生成メトリクスを実装している。これらは、ドキュメントの類似性に基づくメトリクス、尤度ベースのメトリクス、発散ベースのメトリクスに分類される。
        * EmbSim: $$EmbSim=log(\sum_{i=1}^{N}cos(W_{i}^{\prime},W_{i})/N)$$
        * NLL-oracle: {{< math >}}$$NLL_{oracle}=-\mathbb{E}_{Y_{1:T-G_{\rho}}}[\sum_{t=1}^{T}log(G_{oracle}(y_{t}|Y_{1:t-1}))]$${{< /math >}}  
        * NLL-test: {{< math >}}$$NLL_{test}=-\mathbb{B}_{Y_{1:T-G_{teal}}}[\sum_{t=1}^{T}log(G_{\theta}(y_{t}|Y_{1:t-1}))]$${{< /math >}}  


* **実験**: 合成データと実データ（COCO 画像キャプション）を使用して実験が行われた。$NLL_{oracle}$ と $NLL_{test}$ は合成データトレーニングに適用され、BLEU スコア、Self-BLEU スコア、EmbSim は実データトレーニングに適用された。LeakGAN は多くのメトリクスで良好な性能を示した。

## 貢献
* **Texygen ベンチマーク プラットフォームの導入**: オープン ドメイン テキスト生成モデルの研究をサポートする、オープンソースのベンチマーク プラットフォームをリリースした。
* **多数のベースラインモデルと評価メトリクスの実装**: Texygen は、多数のベースラインモデルと、生成テキストの多様性、品質、一貫性を評価するためのさまざまなメトリクスを実装している。
* **研究の標準化と再現性の向上への貢献**: このプラットフォームは、テキスト生成に関する研究の標準化、研究作業の再現性の向上、およびより高度なアプリケーションの奨励に役立つことが期待される。
* **新しいメトリクスの提案**: EmbSim や Self-BLEU といった新しい評価メトリクスを提案した。
* **既存モデルの包括的な比較研究**: さまざまなメトリクスを用いて、既存のテキスト生成モデルの包括的な比較研究を実施した。

## 評価メトリクス

### 1. ドキュメント類似性ベースのメトリクス (Document Similarity based Metrics)
生成されたドキュメントの品質を測る最も直感的な方法は、それらが自然言語、つまりトレーニングデータセットにどれほど似ているかです。

* **BLEU (Bilingual Evaluation Understudy)**
    * 文やドキュメント間の単語の類似性を評価するために広く使われているメトリクスです。

* **EmbSim (Embedding Similarity)**
    * BLEUに触発され、提案されたメトリクスで、「embedding similarity」の略です。
    * 単語ごとに文を比較するのではなく、単語埋め込みを比較します。
    * まず、実際のデータでskip-gramモデルを用いて単語埋め込みを評価します。
    * 各単語埋め込みについて、他の単語とのコサイン類似度を計算し、これを実データの類似性行列 $W$ として定式化します。ここで、$W_{i,j}=cos(e_{i},e_{j})$ であり、$e_i, e_j$ は実データからの単語iとjの単語埋め込みです。
    * 同様に、生成データから同じskip-gramモデルを用いて単語埋め込み $e'_i, e'_j$ を得て、類似性行列 $W'$ を得ます。
    * EmbSimは以下のように定義されます:
        $EmbSim=log(\sum_{i=1}^{N}cos(W_{i}^{\prime},W_{i})/N)$
        ここで、$N$ は総単語数、$W_i$ と $W'_i$ はそれぞれ $W$ と $W'$ のi番目の列を示します。

---
### 2. 尤度ベースのメトリクス (Likelihood-based Metrics)
真のデータ分布 $p$ とモデルからの生成データ分布 $q$ の間のクロスエントロピーを最小化することを目指す最尤推定（MLE）に基づいて、データの適合度やモデルの良さを尤度を測定することで評価するメトリクスです。これらのモデルは、データだけでなくモデルに関する詳細も必要とします。

* **NLL-oracle (Negative Log-Likelihood oracle)**
    * 元々はSeqGANで導入されたもので、特に合成データ実験に適用され、生成されたデータがオラクル言語モデルによってどれだけうまく適合されているかを示します。
    * $NLL_{oracle}$ では、ランダムに初期化されたLSTMが真のモデル、つまりオラクルとみなされます。
    * テキスト生成モデルは、オラクルLSTMにおける生成データの平均負の対数尤度、すなわち $\mathbb{E}_{x\sim q}log~p(x)$ （$x$ は生成データを指す）を最小化する必要があります。
    * LSTMが真のモデルとみなされるため、このメトリクスは各文に対して単語ごとに平均損失を計算できます:
        {{< math >}}$$NLL_{oracle}=-\mathbb{E}_{Y_{1:T-G_{\rho}}}[\sum_{t=1}^{T}log(G_{oracle}(y_{t}|Y_{1:t-1}))]$${{< /math >}}
        ここで、$G_{oracle}$ はオラクルLSTMを、$G_{\theta}$ は生成モデルを示します。

* **NLL-test (Negative Log-Likelihood test)**
    * 提案されたメトリクスで、$NLL_{oracle}$ と対になるもので、モデルが実際のテストデータに適合する能力を評価します。
    * {{< math >}}$$NLL_{test}=-\mathbb{E}_{Y_{1:T \sim G_{real}}}[\sum_{t=1}^{T}log(G_{\theta}(y_{t}|Y_{1:t-1}))]$${{< /math >}}
        ここで、$G_{real}$ は実データの分布を示します。
    * $NLL_{test}$ は、$G_{\theta}(y_{t}|Y_{1:t-1})$ が特定の単語の尤度を計算するためにジェネレータに基づいて以前の単語に基づいて関与するため、RNNのような自己回帰ジェネレータにのみ適用可能です。

### 3. 発散ベースのメトリクス (Divergence based Metrics)
GANモデルはしばしばモード崩壊問題に悩まされ、ジェネレータが単一のサンプルまたは非常に類似したサンプルの小さなファミリーのみを生成するように崩壊する可能性があります。したがって、オープン ドメイン テキスト生成タスクでは、より多様なパターンを生成することを奨励するメトリクスが含まれます。

* **Self-BLEU**
    * 生成されたデータの多様性を評価するために提案されたメトリクスです。
    * BLEUは2つの文がどれほど類似しているかを評価することを目的としているため、生成されたコレクション内で1つの文が残りの文とどれほど類似しているかを評価するためにも使用できます。
    * 1つの文を仮説とし、他の文を参照として、生成された各文に対してBLEUスコアを計算し、その平均BLEUスコアをドキュメントのSelf-BLEUと定義します。
    * Self-BLEUスコアが高いほど、ドキュメントの多様性が低く、GANモデルのモード崩壊が深刻であることを意味します。