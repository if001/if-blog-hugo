---
title: "Language Model Can Listen While Speaking (AI論文要約)"
slug: "paper16"
tags: ["nlp","deeplearning", "paper_summary"]
date: "2025-01-18T14:00:00+09:00"
draft: false
---

AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。

https://arxiv.org/abs/2408.02622

## どんなもの

本論文は、リアルタイムの双方向音声対話を実現する、Listening-while-Speaking Language Model (LSLM) を提案している。LSLMは、音声生成チャネルとリアルタイム音声入力チャネルの両方を備えた、エンドツーエンドのモデルである。音声生成にはトークンベースのdecoder-only TTS、音声入力にはストリーミングSelf-Supervised Learning (SSL) エンコーダを使用し、両チャネルを融合することで、自動回帰的な音声生成とリアルタイムのターンテイク検出を行う。


## 先行研究と比べてどこがすごいの？

先行研究のSpeech Language Model (SLM) はターンベースの会話に限定されており、リアルタイムの音声状況や割り込みに対応できないという限界があった。一方、LSLMは、**Full Duplex Modeling (FDM)** を実現することで、音声生成中にリアルタイムで音声入力を処理し、割り込みに対応できる。既存のモデルは、テキスト中心のLLMをベースに外部のASRとTTSモジュールを必要としていたため、レイテンシが問題となり、パラリンギスティックな能力も不足していたが、LSLMはSLM自体にFDM能力を持たせることで、これらの問題を 解決している。また、ノイズへの頑健性と未知の話者への感度も実験で示されている。


## 技術や手法のきもはどこにある？

LSLMの核となる技術は、音声生成チャネルと音声入力チャネルの同時処理と融合にある。音声生成には、リアルタイム性を重視したトークンベースのdecoder-only TTSを使用。音 声入力には、ストリーミング処理可能なvq-wav2vecを用いたSSLエンコーダを使用する。両チャネルの融合戦略として、Early Fusion、Middle Fusion、Late Fusionの3つの手法を 検討し、Middle Fusionが音声生成とリアルタイム対話のバランスにおいて最適であることを示している。さらに、割り込みを検知するために、IRQ (Interruption Request) トー クンを導入している。


## どうやって有効だと検証した？

LSLMの有効性を検証するために、**Command-based FDM** と **Voice-based FDM** の2つの実験設定を用いた評価を行った。Command-based FDMでは、特定のコマンドによる割り込み、Voice-based FDMでは、未知の話者による様々な単語による割り込みをシミュレートした。評価指標としては、音声生成能力の評価にWord Error Rate (WER)、対話能力の評価 にPrecision、Recall、F1スコアを用いた。結果、LSLMはノイズに頑健であり、未知の話者からの割り込みにも感度良く反応し、既存システムへの影響を最小限に抑えながら双方向通信を実現できることを示した。


## 議論はあるか

論文では、Middle Fusionが最適な融合戦略であると結論付けているが、データセットやモデルアーキテクチャによっては、他の融合戦略がより良い結果を示す可能性もある。また、Voice-based FDMにおけるWERの上昇は、リアルタイムのターンテイク問題の複雑さを示唆しており、さらなる改善の余地がある。さらに、より現実的なシナリオへの適用や、話 者追跡機能の追加、音声・視覚情報の同時利用など、今後の研究課題が提示されている。