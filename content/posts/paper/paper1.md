---
title: "Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization(AI論文要約)"
slug: "paper1"
tags: ["nlp","deeplearning"]
date: "2025-01-02T10:00:00+09:00"
draft: false
---

AIを使った論文要約です。簡単なサーベイ用で詳細は論文を参照してください。

https://arxiv.org/abs/2410.12949

## どんなもの

本論文は、大規模言語モデル(LLM)から望ましくない知識を削除または修正する「知識のアンラーニングと編集」手法に関する研究です。特に、モデルの特定の機能に関連する構成 要素（回路）を特定することを目指す「メカニズム的解釈可能性」を用いて、アンラーニングと編集の精度と有効性を向上させる手法を提案しています。

## 先行研究と比べてどこがすごいの？

先行研究では、出力の保存に基づいて構成要素を特定する「出力追跡（OT）」手法が用いられてきましたが、編集の堅牢性に課題がありました。わずかなプロンプトの変更でも元の情報が引き出されたり、編集が不十分で、元の回答がモデル内に残存したりする問題がありました。

本研究では、予測可能な中間状態を持つ高レベルのメカニズムに基づいて構成要素を特定する手法を提案し、特に「事実の参照メカニズム」に関連する構成要素に編集/アンラーニ ングを局所化することで、以下の点で先行研究を凌駕しています。

1. 堅牢性の向上: 異なる入力/出力形式においても、より堅牢な編集/アンラーニングを実現します。

1. 再学習への耐性: 望ましくない情報の再学習を防ぎます。

1. 副作用の軽減: 意図しない副作用を削減します。

1. 潜在知識の攪乱: 特定の局所化された編集は、他のベースラインよりもモデル内の潜在知識をより強く攪乱し、様々な攻撃に対してより堅牢なアンラーニングを実現します 。

## 技術や手法のきもはどこにある？

本研究の核心は、「事実の参照メカニズム（FLU）」に焦点を当てた「メカニズム的アンラーニング」です。

- FLUの特定: モデル内部の活性化を分析し、事実の参照と属性抽出に関連するMLP層を特定します（Sports Factsデータセットではプローブを用い、CounterFactデータセットではパスパッチングを用いています）。

- 局所化: FLUメカニズムを実装する構成要素にのみ編集/アンラーニングを局所化します。

- 重み更新: 局所化された構成要素の重みを勾配降下法を用いて更新します。損失関数は、望ましくない事実の確率を最小化し、残りの事実の確率を最大化する項と、一般言語モデリング能力を維持するための項から構成されます。

## どうやって有効だと検証した？

様々なデータセット（Sports Facts、CounterFact）、モデル（Gemma-7B、Gemma-2-9B、Llama-3-8b）、評価方法を用いて、提案手法の有効性を検証しました。

- プロンプトベース評価: 編集後のモデルが、元の情報、編集後の情報、関連のない情報をどの程度想起できるかを評価しました。多様なプロンプト形式（通常のプロンプト 、多肢選択式質問、言い換えられたプロンプト、類似事実を含むプロンプト）を用いて、編集の堅牢性を検証しました。

- 敵対的再学習評価: 編集されたモデルを、削除された事実の一部を用いて再学習させ、元の情報がどの程度回復するかを評価しました。

- 潜在知識分析: プローブを用いて、モデル内部表現における元の情報と編集後の情報の表現の変化を分析しました。

- パラメータ効率性: 重みマスクを用いて、編集のサイズを制御し、パラメータ効率性を検証しました。

## 議論はあるか？

先行研究では、局所化がモデル編集に有用でないという主張がありましたが、本研究は、すべての局所化手法が等しいわけではないことを示しています。出力追跡（OT）手法は、容易に局所化できる出力層に焦点を当てるため、堅牢性に欠ける可能性があります。一方、FLU手法は、知識の源泉に直接作用するため、より堅牢な編集/アンラーニングを実現します。